{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce4a70-5e87-49c5-b7fd-6bbae2866220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Implement Page Rank Algorithm. (Use python or beautiful soup for implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2963bf-783a-416e-a122-e3ef539b499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.029220024315633055, 1: 0.013178046038622323, 2: 0.01298395312167649, 3: 0.013568986982610786, 4: 0.012780141376184075, 5: 0.013159264936689043, 6: 0.012574833025542645, 7: 0.01255807050225112, 8: 0.012773473116328848, 9: 0.013162730587953895, 10: 0.010406075051523841, 11: 0.012968611521553833, 12: 0.012551602046972584, 13: 0.012970460556007432, 14: 0.012997821934378382, 15: 0.012568412417128031, 16: 0.012554691754219532, 17: 0.012961998721781245, 18: 0.013179415576964127, 19: 0.012951814191034519, 20: 0.01316680838894304, 21: 0.012953813502760578, 22: 0.013774701730934216, 23: 0.01337983844127945, 24: 0.01274501851295722, 25: 0.01316395859973783, 26: 0.013362879722658887, 27: 0.012952237248468964, 28: 0.013375995620356584, 29: 0.012963992508250512, 30: 0.013186911657565654, 31: 0.013162108162540728, 32: 0.013164807030920992, 33: 0.012770746032099335, 34: 0.013375766165547098, 35: 0.013568986982610786, 36: 0.012764625267483733, 37: 0.012959054845302033, 38: 0.012565248368754167, 39: 0.01276353103691931, 40: 0.013169746950519451, 41: 0.012779263265041665, 42: 0.02736017984457666, 43: 0.027012709249186265, 44: 0.026625552390910297, 45: 0.02629476189957703, 46: 0.027613192669654577, 47: 0.02554201380453328, 48: 0.025213953480708113, 49: 0.024939560999723717, 50: 0.024513989976130923, 51: 0.02380324104546, 52: 0.02380092921861036, 53: 0.023411448164257973, 54: 0.023067025405007994, 55: 0.02286955559416667, 56: 0.022627989522192693, 57: 0.02215014893389898, 58: 0.021639295729059038, 59: 0.021373984255637475}\n",
      "NetworkX's built-in PageRank results:\n",
      "{0: 0.029220024315633066, 1: 0.013178046038622323, 2: 0.01298395312167649, 3: 0.013568986982610786, 4: 0.012780141376184077, 5: 0.013159264936689043, 6: 0.012574833025542645, 7: 0.01255807050225112, 8: 0.012773473116328846, 9: 0.013162730587953893, 10: 0.010406075051523841, 11: 0.012968611521553833, 12: 0.012551602046972584, 13: 0.012970460556007432, 14: 0.01299782193437838, 15: 0.012568412417128031, 16: 0.01255469175421953, 17: 0.012961998721781245, 18: 0.013179415576964127, 19: 0.012951814191034519, 20: 0.01316680838894304, 21: 0.012953813502760578, 22: 0.013774701730934216, 23: 0.01337983844127945, 24: 0.012745018512957219, 25: 0.01316395859973783, 26: 0.013362879722658885, 27: 0.012952237248468963, 28: 0.013375995620356584, 29: 0.012963992508250512, 30: 0.013186911657565654, 31: 0.013162108162540726, 32: 0.01316480703092099, 33: 0.012770746032099333, 34: 0.013375766165547098, 35: 0.013568986982610786, 36: 0.012764625267483731, 37: 0.012959054845302033, 38: 0.012565248368754165, 39: 0.01276353103691931, 40: 0.013169746950519451, 41: 0.012779263265041663, 42: 0.02736017984457667, 43: 0.027012709249186265, 44: 0.0266255523909103, 45: 0.026294761899577038, 46: 0.027613192669654583, 47: 0.025542013804533283, 48: 0.025213953480708116, 49: 0.02493956099972372, 50: 0.024513989976130926, 51: 0.02380324104546, 52: 0.023800929218610357, 53: 0.02341144816425797, 54: 0.02306702540500799, 55: 0.022869555594166667, 56: 0.022627989522192693, 57: 0.022150148933898973, 58: 0.021639295729059038, 59: 0.021373984255637475}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx  # Importing networkx to handle graph structures\n",
    "\n",
    "# PageRank algorithm implementation\n",
    "def pagerank(G, alpha=0.85, personalization=None, max_iter=100, tol=1.0e-6, nstart=None, weight='weight', dangling=None):\n",
    "    # If the graph is empty, return an empty dictionary\n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "\n",
    "    # If the graph is not directed, convert it to a directed graph\n",
    "    if not G.is_directed():\n",
    "        D = G.to_directed()\n",
    "    else:\n",
    "        D = G\n",
    "    \n",
    "    # Create a stochastic graph, which means normalizing the edge weights\n",
    "    W = nx.stochastic_graph(D, weight=weight)\n",
    "    N = W.number_of_nodes()  # Total number of nodes in the graph\n",
    "    \n",
    "    # Choose a starting vector if not provided\n",
    "    if nstart is None:\n",
    "        # If no starting vector, distribute rank equally among all nodes\n",
    "        x = dict.fromkeys(W, 1.0 / N)\n",
    "    else:\n",
    "        # If a starting vector is provided, normalize it\n",
    "        s = float(sum(nstart.values()))\n",
    "        x = dict((k, v / s) for k, v in nstart.items())\n",
    "    \n",
    "    # Handle personalization (bias towards certain nodes)\n",
    "    if personalization is None:\n",
    "        # If no personalization is given, distribute rank equally among all nodes\n",
    "        p = dict.fromkeys(W, 1.0 / N)\n",
    "    else:\n",
    "        # Ensure personalization vector covers all nodes in the graph\n",
    "        missing = set(G) - set(personalization)\n",
    "        if missing:\n",
    "            raise NetworkXError(f'Personalization dictionary must have a value for every node. Missing nodes {missing}')\n",
    "        # Normalize the personalization vector\n",
    "        s = float(sum(personalization.values()))\n",
    "        p = dict((k, v / s) for k, v in personalization.items())\n",
    "    \n",
    "    # Handle dangling nodes (nodes with no outgoing edges)\n",
    "    if dangling is None:\n",
    "        # If no specific dangling vector, use the personalization vector\n",
    "        dangling_weights = p\n",
    "    else:\n",
    "        # Ensure dangling vector covers all nodes in the graph\n",
    "        missing = set(G) - set(dangling)\n",
    "        if missing:\n",
    "            raise NetworkXError(f'Dangling node dictionary must have a value for every node. Missing nodes {missing}')\n",
    "        # Normalize the dangling vector\n",
    "        s = float(sum(dangling.values()))\n",
    "        dangling_weights = dict((k, v / s) for k, v in dangling.items())\n",
    "    \n",
    "    # Identify the dangling nodes (nodes with no outgoing edges)\n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
    "    \n",
    "    # Perform power iteration: this is the main loop of the algorithm\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x  # Store the previous iteration's rank vector\n",
    "        x = dict.fromkeys(xlast.keys(), 0)  # Initialize a new vector for this iteration\n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes)  # Account for dangling nodes\n",
    "        \n",
    "        for n in x:\n",
    "            # For each node, sum the contributions from its neighbors\n",
    "            for nbr in W[n]:\n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight]\n",
    "            \n",
    "            # Add contributions from the dangling nodes and the personalization vector\n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n]\n",
    "        \n",
    "        # Check convergence: if the L1 norm (absolute difference) is smaller than the tolerance, we stop\n",
    "        err = sum([abs(x[n] - xlast[n]) for n in x])\n",
    "        if err < N * tol:\n",
    "            return x  # Return the final PageRank values\n",
    "\n",
    "    # If the algorithm did not converge within the maximum iterations, raise an error\n",
    "    raise NetworkXError(f'Pagerank: power iteration failed to converge in {max_iter} iterations.')\n",
    "\n",
    "# Example usage of the pagerank function\n",
    "import networkx as nx\n",
    "\n",
    "# Generate a random graph using BarabÃ¡si-Albert model (scale-free network)\n",
    "G = nx.barabasi_albert_graph(60, 41)  # 60 nodes and each new node has 41 edges\n",
    "\n",
    "# Compute the PageRank using the custom pagerank function\n",
    "pr = pagerank(G, alpha=0.4)\n",
    "\n",
    "# Print the resulting PageRank values for each node in the graph\n",
    "print(pr)\n",
    "\n",
    "# Alternatively, use NetworkX's built-in PageRank function\n",
    "pr_builtin = nx.pagerank(G, 0.4)  # 0.4 is the damping factor\n",
    "print(\"NetworkX's built-in PageRank results:\")\n",
    "print(pr_builtin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a898e-03a2-4020-8f2e-4680f0ed1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Breakdown:\n",
    "\n",
    "# Imports:\n",
    "# - networkx: Used to handle graph creation and manipulation.\n",
    "\n",
    "# pagerank() Function Parameters:\n",
    "# - G: The input graph (must be a directed graph).\n",
    "# - alpha: Damping factor (usually set between 0.85 and 0.9).\n",
    "# - personalization: A dictionary that assigns custom rank values to nodes (used to bias the algorithm towards specific nodes).\n",
    "# - max_iter: The maximum number of iterations the algorithm will run before stopping.\n",
    "# - tol: The tolerance for convergence. If the sum of absolute differences between iterations is smaller than this value, the algorithm will stop.\n",
    "# - nstart: A dictionary that initializes the starting PageRank values (optional).\n",
    "# - weight: The weight of the edges in the graph (default is 'weight').\n",
    "# - dangling: A dictionary to handle dangling nodes, or nodes with no outgoing edges.\n",
    "\n",
    "# Handling the Graph:\n",
    "# - If the graph is not directed, it is converted to a directed graph.\n",
    "# - A stochastic graph (W) is created, where each edge is normalized to form a valid transition probability.\n",
    "\n",
    "# Initial Vector:\n",
    "# - The initial PageRank vector (x) is set either as equal distribution (if nstart is None) or from the given starting vector nstart.\n",
    "\n",
    "# Personalization:\n",
    "# - If personalization is not provided, the rank is evenly distributed across all nodes.\n",
    "# - If provided, it is normalized to sum to 1.\n",
    "\n",
    "# Dangling Nodes:\n",
    "# - A \"dangling node\" has no outgoing edges. The algorithm handles these by redistributing their rank using the personalization vector (or a provided dangling vector).\n",
    "\n",
    "# Power Iteration:\n",
    "# - The main iterative loop performs the power iteration process to update the PageRank of each node.\n",
    "# - The rank is updated based on the previous iteration's rank and contributions from neighbors and dangling nodes.\n",
    "# - The algorithm stops when the L1 norm of the change in ranks is below the specified tolerance, or when the maximum number of iterations is reached.\n",
    "\n",
    "# Return:\n",
    "# - The function returns the computed PageRank values if convergence is reached.\n",
    "# - Otherwise, it raises an error if convergence isn't achieved within the given iterations.\n",
    "\n",
    "# Example Use Case:\n",
    "# - A random graph is created using the BarabÃ¡si-Albert model (nx.barabasi_albert_graph()), which generates a scale-free network.\n",
    "# - The pagerank() function is applied to this graph with a damping factor (alpha=0.4), and the resulting PageRank values are printed.\n",
    "# - The NetworkX built-in PageRank function is also used to verify the output.\n",
    "\n",
    "# Output:\n",
    "# - The pagerank() function will output a dictionary of nodes with their corresponding PageRank values.\n",
    "# - This can be useful for ranking nodes (pages) in terms of importance or centrality within a network.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
